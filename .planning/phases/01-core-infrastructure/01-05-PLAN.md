---
phase: 01-core-infrastructure
plan: 05
type: execute
wave: 2
depends_on: ["01-02"]
files_modified:
  - src/lib/storage/index.ts
  - src/lib/storage/uploader.ts
  - src/lib/storage/retrieval.ts
  - src/lib/storage/retry.ts
  - .env.example
autonomous: true
user_setup:
  - service: 0g-storage
    why: "Upload reasoning traces to decentralized storage"
    env_vars:
      - name: OG_PRIVATE_KEY
        source: "Generate new wallet or use existing - 0G Testnet faucet needed"
      - name: OG_RPC_URL
        source: "0G docs - https://evmrpc-testnet.0g.ai"
      - name: OG_INDEXER_URL
        source: "0G docs - https://indexer-storage-testnet-turbo.0g.ai"
      - name: OG_FLOW_CONTRACT
        source: "0G docs - 0x22E03a6A89B950F1c82ec5e74F8eCa321a105296"
    dashboard_config:
      - task: "Fund wallet from 0G faucet"
        location: "https://faucet.0g.ai or Discord"

must_haves:
  truths:
    - "0G-01: 0G Storage SDK uploads reasoning traces and returns content hash"
    - "0G-01: Reasoning traces uploaded as JSON with full decision tree metadata"
    - "0G-01: Upload failures retry with exponential backoff (3 attempts)"
    - "0G-02: Content hash stored in job record for on-chain verification"
    - "0G-02: Content hash retrievable from 0G network by hash lookup"
    - "Reasoning trace size validated before upload (~10MB limit)"
  artifacts:
    - path: "src/lib/storage/index.ts"
      provides: "0G Storage module exports"
      exports: ["storageService", "uploadReasoningTrace", "retrieveTrace"]
    - path: "src/lib/storage/uploader.ts"
      provides: "File upload to 0G Storage"
      exports: ["Uploader", "uploadJson", "uploadFile"]
    - path: "src/lib/storage/retrieval.ts"
      provides: "Content retrieval from 0G"
      exports: ["Retriever", "downloadByHash"]
    - path: "src/lib/storage/retry.ts"
      provides: "Retry logic with backoff"
      exports: ["withRetry", "RetryConfig"]
  key_links:
    - from: "uploadReasoningTrace"
      to: "0G Storage Network"
      via: "@0glabs/0g-ts-sdk Indexer.upload()"
    - from: "storageService"
      to: "retry logic"
      via: "wraps all operations with exponential backoff"
---

<objective>
Integrate 0G Storage SDK to upload agent reasoning traces and retrieve them by content hash. Implements 0G-01 (upload reasoning) and 0G-02 (include hash in job record).

Purpose: Provide immutable, verifiable audit trail of agent decisions stored on decentralized storage.
Output: Storage service module with upload, retrieval, and retry capabilities.
</objective>

<execution_context>
@/home/julius/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/julius/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/REQUIREMENTS.md
@.planning/phases/01-core-infrastructure/01-CONTEXT.md
@.planning/phases/01-core-infrastructure/01-RESEARCH.md
@.planning/phases/01-core-infrastructure/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install 0G SDK and configure storage client</name>
  <files>src/lib/storage/index.ts, .env.example</files>
  <action>
    Set up 0G Storage SDK and configuration:
    1. Install 0G SDK: `npm install @0glabs/0g-ts-sdk ethers`
    2. Create `src/lib/storage/index.ts`:
       - Import { Indexer, ZgFile, getFlowContract } from '@0glabs/0g-ts-sdk'
       - Import { ethers } from 'ethers'
       - `ZeroGConfig` interface:
         * chainId: 16602
         * rpcUrl: string
         * indexerUrl: string
         * flowContractAddress: string
         * privateKey: string
       - `StorageService` class:
         * indexer: Indexer
         * signer: ethers.Wallet
         * flowContract: Contract
         * constructor(config: ZeroGConfig)
         * initialize(): Promise&lt;void&gt; (sets up indexer, signer, contract)
       - Environment-based config loading:
         ```typescript
         export const storageConfig: ZeroGConfig = {
           chainId: 16602,
           rpcUrl: process.env.OG_RPC_URL || 'https://evmrpc-testnet.0g.ai',
           indexerUrl: process.env.OG_INDEXER_URL || 'https://indexer-storage-testnet-turbo.0g.ai',
           flowContractAddress: process.env.OG_FLOW_CONTRACT || '0x22E03a6A89B950F1c82ec5e74F8eCa321a105296',
           privateKey: process.env.OG_PRIVATE_KEY || '',
         }
         ```
    3. Update `.env.example` with 0G variables:
       ```
       # 0G Storage Configuration
       OG_PRIVATE_KEY=your_private_key_here
       OG_RPC_URL=https://evmrpc-testnet.0g.ai
       OG_INDEXER_URL=https://indexer-storage-testnet-turbo.0g.ai
       OG_FLOW_CONTRACT=0x22E03a6A89B950F1c82ec5e74F8eCa321a105296
       ```
    4. Add validation:
       - Check OG_PRIVATE_KEY exists on initialization
       - Warn if using default RPC (rate limits)
       - Log chain ID on connect
    
    Per research: 0G Testnet uses Chain ID 16602, Cancun EVM.
    Per research pitfall: Large files timeout — we'll handle in upload logic.
  </action>
  <verify>
    TypeScript compiles: `npx tsc --noEmit src/lib/storage/index.ts`
    Check SDK installed: `npm list @0glabs/0g-ts-sdk`
  </verify>
  <done>
    0G SDK installed, StorageService configured with testnet settings
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement upload with retry logic</name>
  <files>src/lib/storage/uploader.ts, src/lib/storage/retry.ts</files>
  <action>
    Create upload functionality with exponential backoff:
    1. Create `src/lib/storage/retry.ts`:
       - `RetryConfig` interface:
         * maxRetries: number (default: 3)
         * baseDelayMs: number (default: 1000)
         * maxDelayMs: number (default: 10000)
       - `withRetry&lt;T&gt;(fn: () =&gt; Promise&lt;T&gt;, config?: RetryConfig): Promise&lt;T&gt;`:
         * Wraps async function with retry loop
         * Exponential backoff: delay = baseDelay * 2^attempt
         * Jitter: add random 0-1000ms to prevent thundering herd
         * Log each retry attempt
         * Throw last error if all retries exhausted
       - Error classification:
         * `isRetryableError(error): boolean` — check if error is timeout, network, rate limit
         * Don't retry on auth errors or invalid input
    2. Create `src/lib/storage/uploader.ts`:
       - `UploadResult` interface:
         * rootHash: string (Merkle root — the content hash)
         * txHash: string (transaction hash)
         * size: number
         * uploadedAt: Date
       - `Uploader` class:
         * constructor(storageService: StorageService)
         * uploadJson(data: object, filename?: string): Promise&lt;UploadResult&gt;:
           - Convert object to JSON string
           - Create temporary file or Buffer
           - Call uploadFile with the data
         * uploadFile(filePath: string): Promise&lt;UploadResult&gt;:
           - Use ZgFile.fromFilePath() or ZgFile.fromBlob()
           - Calculate Merkle tree: file.merkleTree()
           - Upload via indexer.upload()
           - Return rootHash and txHash
       - Integration with retry:
         * Wrap upload operations with withRetry()
         * Config: 3 retries, 1s base delay
       - Error handling:
         * StorageError class with codes: UPLOAD_FAILED, FILE_TOO_LARGE, NETWORK_ERROR
         * Log detailed errors for debugging
    3. Add size limits:
       - Warn if file > 10MB (per research pitfall about timeouts)
       - Suggest chunking for large files
    
    Per user discretion: Error handling and retry strategies for 0G uploads.
    Per research: Use exponential backoff, handle timeouts for large files.
  </action>
  <verify>
    TypeScript compiles: `npx tsc --noEmit src/lib/storage/uploader.ts src/lib/storage/retry.ts`
  </verify>
  <done>
    Uploader class with JSON upload, Merkle tree calculation, and 3-retry exponential backoff
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement retrieval and reasoning trace upload</name>
  <files>src/lib/storage/retrieval.ts, src/lib/storage/index.ts</files>
  <action>
    Create retrieval and high-level reasoning trace functions:
    1. Create `src/lib/storage/retrieval.ts`:
       - `Retriever` class:
         * constructor(storageService: StorageService)
         * downloadByHash(rootHash: string, outputPath?: string): Promise&lt;Buffer&gt;:
           - Use indexer.download()
           - Return Buffer or save to file
           - Verify Merkle proof if possible
         * getMetadata(rootHash: string): Promise&lt;object&gt;:
           - Fetch metadata from 0G
           - Return size, timestamp, etc.
       - Integration with retry:
         * Wrap download with withRetry()
         * Handle 404s gracefully (return null)
    2. Update `src/lib/storage/index.ts` with high-level API:
       - `uploadReasoningTrace(trace: ReasoningTrace): Promise&lt;string&gt;`:
         * Takes ReasoningTrace object
         * Generates filename: `trace-${jobId}-${timestamp}.json`
         * Calls uploader.uploadJson()
         * Returns rootHash (content hash)
         * Logs success with hash
       - `retrieveTrace(rootHash: string): Promise&lt;ReasoningTrace&gt;`:
         * Downloads by hash
         * Parses JSON
         * Returns ReasoningTrace object
         * Validates structure
       - `storageService` singleton instance
    3. Add validation:
       - Verify trace has required fields before upload
       - Check hash format (hex string)
       - Validate retrieved trace matches schema
    4. Export everything:
       ```typescript
       export { StorageService, storageConfig } from './index'
       export { Uploader, UploadResult } from './uploader'
       export { Retriever } from './retrieval'
       export { withRetry, RetryConfig } from './retry'
       export { uploadReasoningTrace, retrieveTrace, storageService }
       ```
    
    Per requirement 0G-01: Upload agent reasoning JSON to 0G Storage.
    Per requirement 0G-02: Include 0G content hash in on-chain job record.
  </action>
  <verify>
    TypeScript compiles: `npx tsc --noEmit src/lib/storage/retrieval.ts`
    All exports resolve from index.ts
  </verify>
  <done>
    Reasoning trace upload/retrieval implemented, storage module fully exported
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. StorageService initializes with 0G testnet config
2. Upload JSON returns rootHash (content hash)
3. Retry logic attempts 3 times with exponential backoff
4. Retrieve by hash returns original data
5. All modules compile and export correctly
</verification>

<success_criteria>
- 0G Storage SDK (@0glabs/0g-ts-sdk) installed and configured
- StorageService connects to 0G Galileo testnet (Chain ID 16602)
- Upload JSON generates Merkle root hash (content hash)
- Exponential backoff retry: 3 attempts, 1s/2s/4s delays
- Upload result includes rootHash and transaction hash
- Retrieve by rootHash returns original content
- ReasoningTrace type accepted and validated
- Environment variables documented in .env.example
- User setup instructions for wallet funding
- Graceful handling of 404 (hash not found) errors
</success_criteria>

<output>
After completion, create `.planning/phases/01-core-infrastructure/01-05-SUMMARY.md`
</output>
